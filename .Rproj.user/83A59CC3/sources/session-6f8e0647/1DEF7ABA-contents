#' JAOPuTo_get: helper function
#'
#' @description
#' Helper function that sends one or more GET requests to the JAO Publication Tool API,
#' automatically splitting requests into 2-day intervals and applying rate limiting.
#'
#' @param dataset Character string; dataset name in the API ("core", "coreID", "ibwt", "nordic", "swe")
#' @param endpoint Character string; specific endpoint under the dataset in the API
#' @param start Start datetime; (POSIXct, Date, or character convertible to POSIXct)
#' @param end End datetime; (POSIXct, Date, or character convertible to POSIXct)
#' @param skip Integer; pagination offset
#' @param take Integer; pagination size
#' @param rate_limit_per_minute Integer; maximum number of requests per minute
#'
#' @return A tibble containing the combined data returned by all API requests.
#' @examples
#' \dontrun{
#' JAOPuTo_get(
#'   dataset = "core",
#'   endpoint = "api/data/maxNetPos",
#'   start = "2025-11-01 00:00",
#'   end = "2025-11-02 23:00"
#' )
#' }
#' @details
#' The function automatically splits requests into 2-day chunks because the API
#' does not allow long time intervals. Rate limiting is enforced to stay below the
#' API limit of 100 requests per minute.
JAOPuTo_get <- function(dataset,
                        endpoint,
                        start,
                        end,
                        skip = 0L,
                        take = 4000L,
                        rate_limit_per_minute = 100) {

  base_url <- "https://publicationtool.jao.eu"

  sleep_time <- if (is.finite(rate_limit_per_minute) &&
                    rate_limit_per_minute > 0) {
    60 / rate_limit_per_minute
  } else {
    0
  }

  start_utc <- as.POSIXct(start, tz = "UTC")
  end_utc   <- as.POSIXct(end, tz = "UTC") + lubridate::hours(1)

  if (end_utc < start_utc) {
    stop("JAOPuTo_get(): 'end' ligt vóór 'start'.", call. = FALSE)
  }

  to_utc_iso <- function(x) {
    format(x, "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")
  }

  days <- seq(as.Date(start_utc), as.Date(end_utc), by = "2 day")

  dataset_clean  <- sub("/+$", "", dataset)
  endpoint_clean <- sub("^/+", "", endpoint)

  results   <- list()
  meta_list <- list()

  for (i in seq_along(days)) {

    if (i == 1) {
      day_start <- start_utc
    } else {
      day_start <- as.POSIXct(days[i], tz = "UTC")
    }

    if (i == length(days)) {
      day_end <- end_utc
    } else {
      day_end <- as.POSIXct(days[i + 1], tz = "UTC") - 1
    }

    query <- list(
      fromUtc = to_utc_iso(day_start),
      toUtc   = to_utc_iso(day_end),
      skip    = skip,
      take    = take
    )

    url <- paste(base_url, dataset_clean, endpoint_clean, sep = "/")

    resp <- httr::GET(url, query = query)

    if (httr::http_error(resp)) {
      stop(
        "JAOPuTo_get(): HTTP error (",
        httr::status_code(resp), ") voor chunk ",
        i, "/", length(days), ".",
        call. = FALSE
      )
    }

    txt    <- httr::content(resp, as = "text", encoding = "UTF-8")
    parsed <- jsonlite::fromJSON(txt, simplifyDataFrame = TRUE)

    if ("data" %in% names(parsed)) {
      dat <- tibble::as_tibble(parsed$data)
      meta_list[[length(meta_list) + 1L]] <-
        parsed[setdiff(names(parsed), "data")]
    } else {
      dat <- tibble::as_tibble(parsed)
      meta_list[[length(meta_list) + 1L]] <- NULL
    }

    if (nrow(dat) > 0) {
      results[[length(results) + 1L]] <- dat
    }

    if (sleep_time > 0 && i < length(days)) {
      Sys.sleep(sleep_time)
    }
  }

  if (length(results) == 0) {
    out <- tibble::tibble()
  } else {
    out <- tibble::as_tibble(do.call(rbind, results))
  }

  attr(out, "meta") <- meta_list
  out
}
